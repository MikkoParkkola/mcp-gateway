{"data_mtime":1769763561,"dep_hashes":["e557196d7630bbc5d188e222ae51872e01c6440f","797aec9d7cbeba03722815120738adfe6a22c5e2","0c1bcb4dadfab437a820d14a0c3713ca3b3b271e","343ead162c6078d797f73c365daede89be2b20d0","284a6c72c5dc9e6e9c4b46e0f05967f2c57e8727","1d951e191c389692627841676c19b7b5fcb9f26b","d447095c88007808ccc91231c6e4fd3118cab281","dfe602c8b0ec87d813d43afa7c01a5e45dc10eb8","7a40c6ea5c303dfed22fc4a4b612d14521be014e","9f9374ccc6e2df1a91ee9e9d9cd9e3e5001f1b28","fac2e79e417f4ba87a103823cf2b67077fc64f6a","bc096c68f0ff6155228a9a4c578b67b1040ad274","b31942015b5fd09a8b43bd6d0818c03b16ba8cd4","55bdcba20555f7dc1e4993fab806e5623da9ed3b","f4436b9872f01355fc5cbc98ce01686084b09b94","52a795c21d6253ca6fc7f0eff61f891af1cc787f","fd2837f28714ea04d032bccb5e696ee8314b2757","26ff8fe64aecb53bd3ec23140ddd17f78878e9a6","f089b290a55f47149fc59a74bd6cde26b060dd30","ef12ae3eded89bbc2b83c0f5234f9c0b565750cf","2433b62d07bb4783870a9899ec932016c5669212","80a2010e9eb011b20c0b2921e71661fa4ebd4316","cc398d4aa27e05c149456e9e4ef3b100acee0354","9b11b3af0bf77bf150f415d858a301f703dece1b","1ba926414a2722242ce50d9db917d1a5f0357d37"],"dep_lines":[25,6,9,24,30,31,2,6,8,22,23,1,3,5,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,20,5,5,5,10,5,5,5,30,30,30,30,30,30,30,30,30,30],"dependencies":["torch.fx.experimental.proxy_tensor","torch.utils._pytree","torch._higher_order_ops.utils","torch._subclasses.functional_tensor","torch.fx.graph_module","torch.utils.checkpoint","collections.abc","torch.utils","torch._C","torch._ops","torch._subclasses","math","typing","torch","builtins","abc","enum","torch._C._functorch","torch._tensor","torch.autograd","torch.autograd.function","torch.fx._symbolic_trace","torch.fx.proxy","torch.nn.modules.module","torch.utils._python_dispatch"],"error_lines":[],"hash":"8609cbbed4ea79f20f0a18c0bd784a49f79b85a2","id":"torch._higher_order_ops.flex_attention","ignore_all":true,"interface_hash":"3f985dabe8798d6a1d9fdb52628a3d8026d04955","mtime":1769340014,"options":{"other_options":"5b86a6c9d00200393d142204e8b026d3ea9a2b42","platform":"darwin"},"path":"/Users/mikko/.claude/.venv/lib/python3.14/site-packages/torch/_higher_order_ops/flex_attention.py","plugin_data":null,"size":44560,"suppressed":[],"version_id":"1.19.1"}