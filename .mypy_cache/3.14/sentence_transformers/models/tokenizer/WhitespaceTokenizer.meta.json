{"data_mtime":1769764065,"dep_hashes":["0b74f364387e4836b25d7365fa1dd18f773e08c1","d447095c88007808ccc91231c6e4fd3118cab281","43e594a084a3dfbdbfaf76ea36200d0005a5e527","90e162871b808ccca163fbb1879241d43fbd7a48","888bbc6da4693503bbd40986df31a5a9315d7c6f","90e19c8d38c39439449d92ade5b6ddb0c287f81a","ce2df1d627359d22e13502eb87f9639f7faf44b8","f4436b9872f01355fc5cbc98ce01686084b09b94","7866925e06987f7ad19e13e4efaefa33726800b9","52a795c21d6253ca6fc7f0eff61f891af1cc787f","b31942015b5fd09a8b43bd6d0818c03b16ba8cd4"],"dep_lines":[9,7,1,3,4,5,6,1,1,1,1],"dep_prios":[5,5,5,10,10,10,10,5,30,30,30],"dependencies":["sentence_transformers.models.tokenizer.WordTokenizer","collections.abc","__future__","collections","json","os","string","builtins","_typeshed","abc","typing"],"error_lines":[],"hash":"329ee9352575f059213bda3bc22b7d0119290920","id":"sentence_transformers.models.tokenizer.WhitespaceTokenizer","ignore_all":true,"interface_hash":"e5816ffe2061cdcd8fdfea16bf164f26167335ff","mtime":1769460431,"options":{"other_options":"5b86a6c9d00200393d142204e8b026d3ea9a2b42","platform":"darwin"},"path":"/Users/mikko/.claude/.venv/lib/python3.14/site-packages/sentence_transformers/models/tokenizer/WhitespaceTokenizer.py","plugin_data":null,"size":2483,"suppressed":[],"version_id":"1.19.1"}