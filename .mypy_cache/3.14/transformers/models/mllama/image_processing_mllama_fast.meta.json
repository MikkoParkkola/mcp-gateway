{"data_mtime":1769764064,"dep_hashes":["127fe6abc62f60713fc431db6a6a5272c01e9afd","c95be8c76c9659bcca5764c156070c4b17adbcdd","ee738faf070a5242a746c48cd5db35a6af30087f","a65fb09936db8b716b038770ec07efad454c7bd8","39dfd09e984acf71dd3171de83b977d6cbb70825","59347e6368ba7a82b676bbf8c2ae589293bf9e02","9e5cba55701ed8e9e394e3a46914652a62c94696","b31942015b5fd09a8b43bd6d0818c03b16ba8cd4","55bdcba20555f7dc1e4993fab806e5623da9ed3b","47b02f2c728beaa59137ac0f0bc50e6456323569","f4436b9872f01355fc5cbc98ce01686084b09b94","52a795c21d6253ca6fc7f0eff61f891af1cc787f","90e162871b808ccca163fbb1879241d43fbd7a48","fd2837f28714ea04d032bccb5e696ee8314b2757","3eedb58e19d47e1c5d2fdc85e44d486d4d283f5b","7a40c6ea5c303dfed22fc4a4b612d14521be014e","f089b290a55f47149fc59a74bd6cde26b060dd30","095b2166e52f72125049ac16e69ec2a3ece27733","8c0cdc88b65b4c1223930dffd927f4b3958060c2","206ac16aef1715eeb84e5da39d81fcfc802d7a2d","f28465e60408b6924ab4147a2552b68fbd73caaf","039aac59bbd16e356924c2c5859d84be057dc312","209ecd48c24979ba3aa09e4f900da33d3c2290ad","9d30889c7b765010f599a2a14f47dec4f869e9f3"],"dep_lines":[39,38,18,21,31,32,38,15,17,18,1,1,1,1,1,1,1,1,1,1,1,1,1,1,19],"dep_prios":[5,10,10,5,5,5,20,5,10,20,5,30,30,30,30,30,30,30,30,30,30,30,30,30,5],"dependencies":["transformers.models.mllama.image_processing_mllama","transformers.utils.auto_docstring","PIL.Image","transformers.image_processing_utils_fast","transformers.image_transforms","transformers.image_utils","transformers.utils","typing","torch","PIL","builtins","abc","collections","enum","numpy","torch._C","torch._tensor","transformers.feature_extraction_utils","transformers.image_processing_base","transformers.image_processing_utils","transformers.processing_utils","transformers.utils.constants","transformers.utils.generic","transformers.utils.hub"],"error_lines":[],"hash":"fc11c4b7ac580a0abc6ae64d709f45c724057677","id":"transformers.models.mllama.image_processing_mllama_fast","ignore_all":true,"interface_hash":"32f5d23f04e8ec77637496bb40505dc3f1416e73","mtime":1769725021,"options":{"other_options":"5b86a6c9d00200393d142204e8b026d3ea9a2b42","platform":"darwin"},"path":"/Users/mikko/.claude/.venv/lib/python3.14/site-packages/transformers/models/mllama/image_processing_mllama_fast.py","plugin_data":null,"size":15628,"suppressed":["torchvision.transforms.v2"],"version_id":"1.19.1"}