{"data_mtime":1769764064,"dep_hashes":["ef7445724cc74307eba71c9c6d1dbe384a8e1d87","9eb7be21d99021b3e9e2d4183917556ec5f2ded2","8e81f39c9f6a02c1cfef12abd4d9369da9991d33","ebe1cc405c4e5edbbb450db78d9d62854ddd6d33","c95be8c76c9659bcca5764c156070c4b17adbcdd","873ce0c8cae541cb15f5c3e0f58e7c6c2ed37d41","00b62282bb5929af89ccb61ab17ca523b2bb2f7c","e7ad83663b00ea497fd6d7ea9a3ca1f9bdcaf791","0a6ef32f78432c5430cfea8e240b1e7f936518ca","9e5cba55701ed8e9e394e3a46914652a62c94696","b31942015b5fd09a8b43bd6d0818c03b16ba8cd4","55bdcba20555f7dc1e4993fab806e5623da9ed3b","f4436b9872f01355fc5cbc98ce01686084b09b94","52a795c21d6253ca6fc7f0eff61f891af1cc787f","90e162871b808ccca163fbb1879241d43fbd7a48","82e850a550a5311633ba962d71eeb4afc90777c3","7a40c6ea5c303dfed22fc4a4b612d14521be014e","1baf260a7f09ff8a2ef9b3d256d5aac4c74e2765","b3b2bc128cfc04ab2f0fdf5dad3555a5c26a0593","f089b290a55f47149fc59a74bd6cde26b060dd30","c8bf99efe0f6c9fdd8a1ad00606315af129eb8a2","9b11b3af0bf77bf150f415d858a301f703dece1b","3055b1f8a4fe1f9b0924f73ab7f9a6aa7011455c","45311644bc9679519181a5e8b75909f30c02cae5","03cb08eb4095f6222ec4d510000c32458fcd9e92","cf13678bd30924dbd71c79b5aa7d3756a03c19e4","87f3a680ced94cae174a47ae092607c63fb338db","13066ef53dc4083b61da91da4f4f033181802675","209ecd48c24979ba3aa09e4f900da33d3c2290ad","9d30889c7b765010f599a2a14f47dec4f869e9f3","462f9733db4fdc1ec19e4be6c2318ba9e129c041"],"dep_lines":[25,26,27,28,24,24,20,22,23,24,17,19,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,5,5,5,10,10,10,5,5,5,5,10,5,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30],"dependencies":["transformers.models.auto.configuration_auto","transformers.models.auto.modeling_auto","transformers.models.clip.modeling_clip","transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder","transformers.utils.auto_docstring","transformers.utils.logging","torch.nn","transformers.modeling_outputs","transformers.modeling_utils","transformers.utils","typing","torch","builtins","abc","collections","logging","torch._C","torch._C._VariableFunctions","torch._prims_common","torch._tensor","torch.nn.modules.linear","torch.nn.modules.module","torch.nn.parameter","transformers.configuration_utils","transformers.integrations.peft","transformers.modeling_rope_utils","transformers.models.auto.auto_factory","transformers.models.clip.configuration_clip","transformers.utils.generic","transformers.utils.hub","types"],"error_lines":[],"hash":"5a8925643dc6e6e7dfecc3642ddc51c534da8033","id":"transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder","ignore_all":true,"interface_hash":"a7517aaef57494ec884719d1140f9eecd24fb3a1","mtime":1769725021,"options":{"other_options":"5b86a6c9d00200393d142204e8b026d3ea9a2b42","platform":"darwin"},"path":"/Users/mikko/.claude/.venv/lib/python3.14/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py","plugin_data":null,"size":17588,"suppressed":[],"version_id":"1.19.1"}